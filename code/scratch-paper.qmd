---
title: "ENVS 193DS Homework 05"
format: 
  html:
    toc: true
    toc-location: left
    code-fold: true
    theme: yeti
execute: 
  message: false
  warning: false
---

```{r libraries}
library(tidyverse)
library(here)
library(janitor)
library(ggeffects)
library(performance)
library(naniar) # or equivalent
library(flextable) # or equivalent
library(car)
library(broom)
# would be nice to have
#install.packages("corrplot") 
library(corrplot)
#install.packages("AICcmodavg")
library(AICcmodavg)
#install.packages("GGally")
library(GGally)
#install.packages("MuMIn")
library(MuMIn)
```

```{r reading-data}
plant <- read_csv(here("data", "hf109-01-sarracenia.csv")) %>% 
  # make the column names cleaner
  clean_names() %>% 
  # selecting the columns of interest
  select(totmass, species, feedlevel, sla, chlorophyll, amass, num_lvs, num_phylls)
```

```{r missing-data-visualization}
gg_miss_var(plant)
```

Subsetting the data by dropping NAs:

```{r subset-drop-NA}
plant_subset <- plant %>% 
  drop_na(sla, chlorophyll, amass, num_lvs, num_phylls)
```

Create a correlation plot:

(example writing) To determine the realtionships between numerical variables in our dataset, we calculated Pearson's r and visually represented correlation using a correlation plot.

```{r correlation-plot}
# calculate pearson's r for numerical values only
plant_cor <- plant_subset %>% 
  select(feedlevel:num_phylls) %>% 
  cor(method = "pearson")

# creating a correlation plot
corrplot(plant_cor,
         # change the shape of what's in the cells
         method = "ellipse",
         addCoef.col = "black"
         )
```

Create a plot of each variable compared against the others

```{r pairs-plot}
plant_subset %>% 
  select(species:num_phylls) %>% 
  ggpairs()
```

Starting regression here:

(example) To determine how species and physiological characteristics predict biomass, we fit multiple linear models.

```{r null-and-full-models}
# making a null model, which is represented by a one and we only want it from the plant_subset dataset
null <- lm(totmass ~ 1, data = plant_subset)
# now we include all of the variables
full <- lm(totmass ~ species + feedlevel + sla + chlorophyll + amass + num_lvs + num_phylls, data = plant_subset)
```

We visually assess normality and homoscedasticity of residuals using diagnostic plots for the full model:

```{r full-diagnostic}
par(mfrow = c(2,2))
plot(full)
```

For homoscedasticity, this is easier to see in residuals vs fitted, and shows that the red lines are flat (good sign) and the dots are spread out in comparison. Clumped in beginning and then spread out, so a little cone shaped, therefore it is borderline homoscedasticity.

We also tested for normality using the Shapiro-Wilk test (null hypothesis: variable of interest (i.e. the residuals) are normally distributed)

We tested for homoscedasticity using the Breusch-Pagan test (null hypothesis: variable of interest has constant variance).

```{r}
check_normality(full)
check_heteroscedasticity(full)
```

Transform the response variable (take the log 10 or whatever mathematical transformation) to transform your residuals to be normal because most data from the field, is not normal (as we have seen).

```{r}
full_log <- lm(log(totmass) ~ species + feedlevel + sla + chlorophyll + amass + num_lvs + num_phylls, data = plant_subset)

null_log <- lm(log(totmass) ~ 1, data = plant_subset)

plot(full_log)
check_normality(full_log)
check_heteroscedasticity(full_log)
```

Evaluate multicollinearity:

```{r calculate-vif}
car::vif(full_log)
```

We evaluated multicollinearity by calculating generalized variance inflation factor and determined that....

try some models

addressing the question: what set of predictor variables best explores the response?

```{r}
model2_log <- lm(log(totmass) ~ species, data = plant_subset)
```

check assumptions for model 2:

```{r}
plot(model2_log)

check_normality(model2_log)
check_heteroscedasticity(model2_log)
```

compare models using Akaike's Information criterion (AIC) values

```{r}
#AICc is for smaller smaple sizes
#MUMIn  and AIC also work
AICc(full_log)
AICc(model2_log)
AICc(null_log)

MuMIn::AICc(full_log, model2_log, null_log)
MuMIn::model.sel(full_log, model2_log, null_log)
```

The model that seems to be the best is full_log (it is looking for what explains the most variance) because it's value is the lowest. We are looking for the simplest explanation, so what in the full_log explains the variance.

We compared models using AIC and chose the model with the lowest value, which was... (An's words)

## Results

We found that the \_\_\_\_\_\_ model including \_\_\_\_ \_\_\_\_\_ \_\_\_\_\_ predictors, \_\_\_\_\_\_\_\_ (model summary).

```{r}
summary(full_log)

table <- tidy(full_log, conf.int = TRUE) %>% 
  # change the p-value numbers if they're really small
  # change the estimates, standard errors, and t-statistics
  # using mutate
  # make it into a flextable
  flextable() %>% 
  # fit it to the viewer
  autofit()

table
```

use 'ggpredict()' to backtransform estimates

```{r}
model_pred <- ggpredict(full_log, terms = "species", back.transform = TRUE)

# the same as plot(ggpredict(full_log, terms = "species", back.transform = TRUE), add.data = TRUE)
plot(model_pred, add.data = TRUE)

plot(ggpredict(full_log, terms = "chlorophyll", back.transform = TRUE), add.data = TRUE)

plot(ggpredict(full_log, terms = "feedlevel", back.transform = TRUE), add.data = TRUE)

plot(ggpredict(full_log, terms = "sla", back.transform = TRUE), add.data = TRUE)

plot(ggpredict(full_log, terms = "amass", back.transform = TRUE), add.data = TRUE)

plot(ggpredict(full_log, terms = "num_lvs", back.transform = TRUE), add.data = TRUE)

plot(ggpredict(full_log, terms = "num_phylls", back.transform = TRUE), add.data = TRUE)

model_pred
```

(totmass \~ species + feedlevel + sla + chlorophyll + amass + num_lvs + num_phylls, data = plant_subset)

## different types of anovas
